<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
<head>
   <meta http-equiv="content-type" content="text/html; charset=utf-8" />
   <title>Nate Silvers Forecast Would Have Done Better Had</title>
   <meta name="author" content="Thomas Pendergast Vladeck" />
   <!-- syntax highlighting CSS -->
   <link rel="stylesheet" href="/css/syntax.css" type="text/css" />

   <!-- Homepage CSS -->
   <link rel="stylesheet" href="/css/screen.css" type="text/css" media="screen, projection" />

   <!-- Typekit -->
   <script type="text/javascript" src="http://use.typekit.com/jpd0pfm.js"></script>
   <script type="text/javascript">try{Typekit.load();}catch(e){}</script>
</head>
<body>


<div class="site">
  <div class="title">
    <a href="/">Thomas Pendergast Vladeck</a>
    <a class="extra" href="/">home</a>
  </div>

  <div id="title">
    <h1>Nate Silvers Forecast Would Have Done Better Had</h1>
</div>

<div id="post">
<p>[gallery]</p>
<p>Nate Silver&#8217;s forecast would have done better had he gotten a few wrong. </p>
<p>I really like 538 and they have done a great job. I have one minor quibble with how they represent their forecasts and their results. 538&#8217;s forecasts are <em>not</em> binary predictions, they are probability estimates. Meaning, that of all the races he projects to be at 70% probability, the winner should be the leading candidate 70% of the time - not 100% of the time. But 538 and many others are saying that he got 50/50 states right, and that confuses the picture a lot. What does it mean to call Florida &#8220;correctly" when the model gave Obama a 50.1 chance of winning?</p>
<p>The example I used when explaining it to some friends was that if a weatherman, for 10 straight days, said there was a 55% chance of rain, and it rained every day - you could say that the weatherman correctly predicted the weather every day, but the correct interpretation is that his estimates were too low. </p>
<p>The code below simply takes 538&#8217;s estimates right before the election, with the probability figure being that which 538 assigned to the eventual winner. The code simply assumes that 538&#8217;s probability estimates were exactly correct, and shows the distribution of states that would be in error in a run of 10,000 simulations. As you can see, if 538&#8217;s estimates were exactly correct, it&#8217;s  significantly more likely that he would have gotten 1, 2, or 3 states wrong than none at all. </p>
<p>This is not to say that his estimates <em>weren&#8217;t</em> spot on - there is a good chance they were - I only want to point out that there is a little bit more going on than saying that 538 got 50/50 states &#8220;right".</p>
<div class="gist"><a href="https://gist.github.com/4046576">https://gist.github.com/4046576</a></div>

</div>



  <div class="footer">
    <div class="contact">
      <p>
        Thomas Pendergast Vladeck 
        <br />
        Managing Director of
          <a href="https://www.gradientmetrics.com/">Gradient Metrics</a>
        <br />
        thomas.vladeck@gmail.com
      </p>
    </div>
  </div>
</div>



<!-- Google Analytics -->
<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-36795403-1);
pageTracker._trackPageview();
</script>
<!-- Google Analytics end -->

</body>
</html>
